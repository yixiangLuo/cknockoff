```{r setup, echo = FALSE, message=FALSE, warning=FALSE}
# set default knitr chunks
knitr::opts_chunk$set(
  echo = FALSE,  # don't print the code chunk
  warning = FALSE,  # don't print warnings
  message = FALSE,  # don't print messages
#  fig.width = 6,  # set default width of figures
 fig.height = 4,  # set default height of figures
#  dpi=300, 
  fig.align = "center",  # always align figure in center
  fig.pos = "H",  # always plot figure at the exact location of the code chunk
  cache = FALSE)  # don't cache results


library(tidyverse)
library(foreach)
library(doParallel)
library(KernSmooth)
library(devtools)

load_all()
```


```{r test_mc_decision}

test_confidence_sequence <- function(alpha, seq_length, n_test = 1000){
    uncovered <- 0
    for(test_i in 1:n_test){
        mean_vec <- c(-1, -1, 0)
        samples <- sample(mean_vec, size = seq_length, replace = T)
        samples <- samples + runif(seq_length, min = -1, max = 1)
        sample_bound <- list(lower = min(mean_vec)-1, upper = max(mean_vec)+1)
        true_mean <- mean(mean_vec)

        samples_unit <- sample_to_unit(samples, sample_bound)
        mean_unit <- sample_to_unit(true_mean, sample_bound)

        mean_covered <- T
        for(step in 1:seq_length){
            if(!m_in_HCS(samples_unit[1:step], m = mean_unit, alpha)$in_HCS){
                mean_covered <- F
                break
            }
        }
        if(!mean_covered){
            uncovered <- uncovered + 1
        }
    }

    print(paste0("alpha: ", alpha, ", fails covering: ", uncovered / n_test))
}

test_decision <- function(rej_alpha, accept_alpha, seq_length, threshold, n_test = 100){
    results <- matrix(rep(0, 4), nrow = 2)
    for(test_i in 1:n_test){
        mean_vec <- c(-1, -1, 0)
        samples <- sample(mean_vec, size = seq_length, replace = T)
        samples <- samples + runif(seq_length, min = -1, max = 1)
        sample_bound <- list(lower = min(mean_vec)-1, upper = max(mean_vec)+1)

        confidence <- F
        for(step in 1:seq_length){
            decision <- make_decision(samples[1:step], sample_bound, threshold, rej_alpha, accept_alpha)
            if(decision$confident){
                results[1, as.integer(decision$reject)+1] <- 1 + results[1, as.integer(decision$reject)+1]
                confidence <- T
                break
            }
        }
        if(!confidence){
            results[2, as.integer(decision$reject)+1] <- 1 + results[2, as.integer(decision$reject)+1]
        }
    }

    results <- results / n_test
    if(mean(mean_vec) <= threshold){
        alpha <- accept_alpha
        rej_type <- "accept"
        data <- results[, 1] / rowSums(results)
    } else{
        alpha <- rej_alpha
        rej_type <- "reject"
        data <- results[, 2] / rowSums(results)
    }

    print(paste0("alpha: ", alpha))
    print(paste0("Confident: ", sum(results[1, ])))
    print(paste0(rej_type, ": ", data[1]))
    print(paste0("Inconfident: ", sum(results[2, ])))
    print(paste0(rej_type, ": ", data[2]))
}

```



```{r test_sampler}
# naively sampling y conditional on Sj
y_condj_sample <- function(y, X, j, sample_size, seed = 1, q_cap = Inf){
    set.seed(seed + 2000)

    n <- NROW(X)

    projj_y <- lm(formula = y ~ X[, -j] + 0)$fitted.values
    radius <- sqrt(sum(y^2) - sum(projj_y^2))

    sample_once <- function(s_size){
        y_sample <- matrix(rnorm(n * s_size), nrow = n)

        y_sample <- y_sample - lm(formula = y_sample ~ X[, -j] + 0)$fitted.values
        y_sample <- scale(y_sample, center = FALSE, scale = sqrt(colSums(y_sample^2)) / radius)
        y_sample <- projj_y + y_sample

        return(y_sample)
    }

    # validate_sample <- function(y_cond, candidates, valid_sample_list){
    #     for(i in candidates){
    #         if(qvals_BH_lm(y_cond[, i], X)[j] <= q_cap){
    #             valid_sample_list <- c(valid_sample_list, i)
    #         }
    #     }
    #     return(valid_sample_list)
    # }

    y_cond <- sample_once(sample_size)
    # valid_sample_list <- validate_sample(y_cond, 1:sample_size, NULL)

    # print(length(valid_sample_list)/sample_size)

    return(y_cond)
}

# cKnockoff for a particular y and and j
cKnockoff_j <- function(y, X, X.pack,
                        alpha = 0.2,
                        H0, seed = 1, mc_size = 100,
                        invest_j = NULL,
                        naive_sampler = T,
                        kn_reg_method = "local_lin_reg",
                        statistic){
    # X <- X_invest
    # y <- y_invest
    invest_mode <- T

    j <- invest_j

    n <- NROW(X)
    p <- NCOL(X)
    df <- n - p


    y.pack <- process_y(X.pack, y)
    Xk_dir <- X.pack$X_res_Xk_basis[, 2]

    Xkn_full <- scale(cbind(X, X.pack$X_kn))

    if(naive_sampler){
        tvals_obs <- lm_to_t(y, X)$tvals
    } else{
        tvals_obs <- y_to_t(y, X.pack$vj_mat, sqrt(y.pack$y_Pi_X_res_norm2 / df))
    }
    pvals_obs <- pvals_t(tvals_obs, df = df, side = "two") # marginal test qvals
    pval_obs <- pvals_obs[j]

    ineq_LR <- matrix(rep(0, 2*mc_size), 2)
    
    fit_on_rest <- glmnet::glmnet(X[, -j], y, lambda = 2 * y.pack$sigmahat_XXk_res/n, intercept=T, standardize=F, standardize.response=F, family="gaussian")
    y.pack$Xy_bias[j] <- t(X[, j]) %*% (X[, -j] %*% fit_on_rest$beta + rep(fit_on_rest$a0, each = n))
    cali_stats_obs <- abs(c(matrix(y, nrow = 1) %*% X) - y.pack$Xy_bias)

    # for investing
    if(invest_mode){
        p_ineq <- data.frame(pval = numeric(), tval = numeric(),
                             ineq_L = numeric(), ineq_R = numeric(),
                             kn_rej = logical(), nokn_rej = logical(),
                             kept = logical())
        pval_mat <- matrix(NA, p, mc_size)
        kn_stats_mc <- matrix(NA, mc_size, p)
        eskn_rej_mc <- matrix(NA, mc_size, p)
        vjy_mc <- rep(NA, mc_size)
        # SRL_est_mc <- rep(NA, mc_size)
        kn_stat_thres <- rep(NA, mc_size)
        # pi0_mc <- rep(NA, mc_size)
        # Rkn_mc <- rep(NA, mc_size)
        # Reskn_mc <- rep(NA, mc_size)
        # qval_invest <- pval_obs
        y_Pi_Xk1_mc <- rep(NA, mc_size)
        pval_mc <- rep(NA, mc_size)
        weights_mc <- NULL
    }


    # knockoff and dBY rejection
    kn_stats_obs <- statistic(X, X.pack$X_kn, y, sigma_tilde = y.pack$sigmahat_XXk_res)
    kn_selected <- kn.select(kn_stats_obs, alpha,
                              selective = T, early_stop = 0)$selected

    init_selected <- j %in% kn_selected


    ## Monte Carlo sample for RB
    # # naive sampler
    if(naive_sampler){
        y_cond <- y_condj_sample(y, X, j, mc_size, seed = seed+j)
        sample_weights <- rep(1, mc_size)
        sigmahat_XXk_res <- rep(y.pack$sigmahat_XXk_res, mc_size)
    }

    # rejection region of the new sampler
    kn_stat_nodes <- kn_stat_sampling(alpha, j, y.pack, X.pack,
                                      node_num = 10,
                                      statistic)
    kn_rej_set <- where_kn_rej(alpha, j, y.pack,
                               X.pack = NULL,
                               statistic, method = kn_reg_method,
                               kn_stat_samples = kn_stat_nodes)
    
    
    cali_rej_set <- where_cali_rej(j, y.pack, X.pack)
    sample_region <- interval_union(kn_rej_set, cali_rej_set)

    sample_res <- y_sampler_cond_Sj(mc_size, cali_rej_set, kn_rej_set, j,
                                    y.pack, X.pack)
    if(!naive_sampler){
        y_cond <- sample_res$y_samples
        sample_weights <- sample_res$sample_weights
        sigmahat_X_res <- sample_res$sigmahat_X_res
        sigmahat_XXk_res <- sample_res$sigmahat_XXk_res

        ineq_bounds <- get_ineq_bound(alpha, p, sample_res$weights)
    }

    if(invest_mode){
        weights_mc <- sample_weights
    }

    ineq <- rep(NA, mc_size)

    for(mc_i in 1:mc_size){

        # compute knockoff stat
        kn_stats <- statistic(X, X.pack$X_kn, y_cond[, mc_i], sigmahat_XXk_res[mc_i])

        ## compute weights
        # make rejection and fdp estimation based on knockoff statistics
        # selective SeqStep: selective = TRUE; SeqStep: selective = FALSE
        kn_result <- kn.select(kn_stats, alpha,
                                selective = T, early_stop = 1)
        kn_selected_mc <- kn_result$selected

        # compute weight
        kn_null_num <- (kn_result$fdp_est * length(kn_selected_mc)) %>% max(1)
        w_tilde <- (j %in% kn_selected_mc) / kn_null_num

        # for investing
        if(invest_mode){
            eskn_rej_mc[mc_i, ] <- (1:p) %in% kn_selected_mc
            kn_stat_thres[mc_i] <- kn_result$W_k_hat
            # pi0_mc[mc_i] <- kn_result$fdp_est
            # Reskn_mc[mc_i] <- length(kn_selected_mc)
        }

        ## compute g*
        # p-values
        if(naive_sampler){
            tvals_mc <- lm_to_t(y_cond[, mc_i], X)$tvals
        } else{
            tvals_mc <- y_to_t(y_cond[, mc_i], X.pack$vj_mat, sigmahat_X_res[mc_i])
        }
        pvals_mc <- pvals_t(tvals_mc, df, side = "two")
        
        if(!naive_sampler && F){
            t_naive <- lm_to_t(y_cond[, mc_i], X)$tvals
            t_new <- y_to_t(y_cond[, mc_i], X.pack$vj_mat, sigmahat_X_res[mc_i])
            print(max(abs(t_new - t_naive)) < 1e-12)
            
            sigma_tilde_naive <- sqrt((sum(y_cond[, mc_i]^2) - 
                   sum((lm(y_cond[, mc_i] ~ cbind(X.pack$X, X.pack$X_kn))$fitted.values)^2)) / (n - 2*p))
            sigma_tilde_new <- sigmahat_XXk_res[mc_i]
            print(max(sigma_tilde_new - sigma_tilde_naive))
            browser()
        }

        # knockoff rejections
        kn_result <- kn.select(kn_stats, alpha,
                                selective = T, early_stop = 0)
        kn_selected_mc <- kn_result$selected
        
        # # for investing
        # if(invest_mode){
        #     Rkn_mc[mc_i] <- length(kn_selected_mc)
        # }

        # R hat
        selected_mc <- kn_selected_mc

        # compute calibration selection
        cali_stat_mc <- abs(sum(X[, j] * y_cond[, mc_i]) - y.pack$Xy_bias[j])
        cali_selected_mc <- ifelse(cali_stat_mc >= cali_stats_obs[j], j, 0)

        # compute g star
        g_star <- (j %in% union(kn_selected_mc, cali_selected_mc)) / length(union(selected_mc, j))

        ineq_LR[, mc_i] <- c(g_star, w_tilde * alpha) * sample_weights[mc_i]
        # for investing
        if(invest_mode){

            pval_invest <- pvals_t(tvals_mc, df, side = "right")
            # if(pval_invest[j] > 0.99) browser()

            p_ineq <- add_row(p_ineq,
                              pval = pval_invest[j],
                              tval = tvals_mc[j],
                              ineq_L = g_star,
                              # ineq_R = w_tilde * alpha,
                              ineq_R = w_tilde * alpha,
                              kn_rej = (j %in% kn_selected_mc),
                              nokn_rej = (j %in% cali_selected_mc),
                              kept = x_in_intervals(tvals_mc[j], sample_region))

            pval_mat[, mc_i] <- pval_invest
            kn_stats_mc[mc_i, ] <- kn_stats
            vjy_mc[mc_i] <- t(X.pack$vj_mat[, j]) %*% y_cond[, mc_i]
            # SRL_est_mc[mc_i] <- (max(abs(t(Xkn_full) %*% y_cond[, mc_i])) +
            #                          max(abs(t(Xkn_full[, j] %*% y_cond[, mc_i])),
            #                              abs(t(Xkn_full[, j + p] %*% y_cond[, mc_i])))) / 2 / sqrt(n-1)

            y_Pi_Xk1_mc[mc_i] <- sum(y_cond[, mc_i] * Xk_dir)
            pval_mc[mc_i] <- pval_invest[j]
        }

        # if(mc_i %% 2 == 0){
        #
        #     ineq_in_rej <- (p_ineq$ineq_L[1:mc_i] - p_ineq$ineq_R[1:mc_i]) * sample_weights[1:mc_i]
        #     ineq_combine <- (ineq_in_rej[seq(1, mc_i-1, length.out = mc_i/2)] + ineq_in_rej[seq(2, mc_i, length.out = mc_i/2)]) / 2
        #     ineq_bounds <- get_ineq_bound(alpha, p, sample_res$weights)
        #
        #     # make decision
        #     decision <- make_decision(ineq_combine[1:(mc_i/2)], ineq_bounds, threshold = 0,
        #                               # rej_alpha = min(0.05, alpha * max(1, length(kn_selected)) / length(candidates)),
        #                               rej_alpha = 0.01,
        #                               acpt_alpha = 0.01)
        #
        #     if(decision$confident){
        #         print(mc_i)
        #         browser()
        #     }
        # }

        # # HCS confidence interval
        # ineq[mc_i] <- (g_star - w_tilde * alpha) * sample_weights[mc_i]
        # if(mc_i %% 2 ==0){
        #     ineq_combine <- (ineq[seq(1, mc_i-1, length.out = mc_i/2)] + ineq[seq(2, mc_i, length.out = mc_i/2)]) / 2
        #
        #     ineq_unit <- sample_to_unit(ineq_combine[1:(mc_i/2)], ineq_bounds)
        #     thr_unit <- sample_to_unit(0, ineq_bounds)
        #     if(!m_in_HCS(ineq_unit, m = thr_unit, alpha = 0.001)){
        #         print(mc_i)
        #     }
        # }

    }

    # test the correctness of the importance sampler and weights by comparing with the naive sampler
    inds_in_rej <- sapply(p_ineq$tval, function(x){
        x_in_intervals(x, sample_region)
    })
    inds_in_rej <- which(inds_in_rej)
    num_in_rej <- length(inds_in_rej)
    ineq_in_rej <- (p_ineq$ineq_L[inds_in_rej] - p_ineq$ineq_R[inds_in_rej]) * sample_weights[inds_in_rej] * num_in_rej / mc_size
    print(paste0("sample_mass (emp): ", num_in_rej / mc_size))
    print(paste0("ineq: ", mean(ineq_in_rej)))
    if(!naive_sampler){
        ineq_combine <- (ineq_in_rej[seq(1, mc_size-1, length.out = mc_size/2)] + ineq_in_rej[seq(2, mc_size, length.out = mc_size/2)]) / 2
        ineq_bounds <- get_ineq_bound(alpha, p, sample_res$weights)
        print(paste0("outside_bound: ", sum((ineq_combine > ineq_bounds$upper) | (ineq_combine < ineq_bounds$lower))))
    }

    ineq_LR_mean <- rowMeans(ineq_LR)
    ineq_selected <- (ineq_LR_mean[1] <= ineq_LR_mean[2])


    return(list(p_ineq = p_ineq, pval_mat = pval_mat, kn_stats_mc = kn_stats_mc,
                eskn_rej_mc = eskn_rej_mc, vjy_mc = vjy_mc,
                # SRL_est_mc = SRL_est_mc,
                kn_stat_thres = kn_stat_thres, sample_weights = sample_weights,
                # qval_invest = qval_invest, 
                # pi0_mc = pi0_mc, Rkn_mc = Rkn_mc, Reskn_mc = Reskn_mc,
                # init_selected = init_selected, ineq_selected = ineq_selected,
                kn_rej_set = kn_rej_set, cali_rej_set = cali_rej_set,
                sample_region = sample_region,
                kn_stat_nodes = kn_stat_nodes,
                y_Pi_Xk1_mc = y_Pi_Xk1_mc, pval_mc = pval_mc,
                weights_mc = weights_mc))
}

# similar to get_fdp_power(), but call dKnockoff_j() for investigation
invest_ineq <- function(n, p, mc_size, X_type, target, alpha, alt_num,
                        y_seed, invest_j,
                        naive_sampler = T,
                        kn_reg_method = "local_lin_reg",
                        statistic = stat.glmnet_coefdiff_lm,
                        cali_var = "pval",
                        n_cores = 6){
    X_seed <- 1
    X <- gene_X(X_type, n, p, X_seed)

    if(X_type == "X_block"){
        pi1 <- 10 / p
        mu1 <- BH_lm_calib(X, pi1, noise = quote(rnorm(n)), "fix", 1, side = "two", nreps = 200, alpha = alpha,
                           target = target, n_cores = n_cores)

        beta <- genmu(p, pi1, mu1, "fix", 1)
    } else{
        pi1 <- alt_num / p
        mu1 <- BH_lm_calib(X, pi1, noise = quote(rnorm(n)), "random", 1, side = "two", nreps = 200, alpha = alpha,
                           target = target, n_cores = n_cores)

        beta <- genmu(p, pi1, mu1, "random", 1)
    }
    # beta[abs(beta) > 1e-4] <- beta[abs(beta) > 1e-4] * (-1)^seq_along(beta[abs(beta) > 1e-4])
    H0 <- beta == 0

    registerDoParallel(n_cores)

    # precompute the matrices related to X
    X <- scale(X, center = FALSE, scale = sqrt(colSums(X^2)))
    X.pack <- process_X(X)


    set.seed(y_seed)
    y <- X %*% beta + rnorm(n)

    ineq_invest <- cKnockoff_j(y, X, X.pack,
                               alpha = alpha,
                               H0, seed = y_seed+100,
                               mc_size = mc_size,
                               invest_j = invest_j,
                               naive_sampler = naive_sampler,
                               kn_reg_method = kn_reg_method,
                               statistic = statistic)


    rejected <- sum((ineq_invest$p_ineq$ineq_L - ineq_invest$p_ineq$ineq_R) *
                        ineq_invest$sample_weights) <= 0
    
    z_norm2 <- sum(y^2) - sum((lm(y ~ X[, -invest_j])$fitted.values)^2)

    return(c(ineq_invest, list(X = X, y = y, z_norm2 = z_norm2,
                               alt = which(!H0), rejected = rejected)))
}
```

```{r utils}
# generate X matrix
gene_X <- function(X_type = "IID_Normal", n, p, X_seed = 1){
    cor_radius <- 5
    set.seed(X_seed)
    if(X_type == "IID_Normal"){
        X <- matrix(rnorm(n*p), n) / sqrt(n)
    } else if(X_type == "Coef_AR"){
        rho <- 0.5

        cov_mat <- solve(rho^(abs(outer(1:p, 1:p, "-"))))

        R <- chol(cov_mat)
        basis <- qr.Q(qr(matrix(rnorm(n*p), n)))
        X <- basis %*% R
    } else if(X_type == "X_AR"){
        rho <- 0.5

        cov_mat <- rho^(abs(outer(1:p, 1:p, "-")))

        R <- chol(cov_mat)
        basis <- qr.Q(qr(matrix(rnorm(n*p), n)))
        X <- basis %*% R
    } else if(X_type == "Homo_Block"){
        rho <- 0.5
        block_size <- 10

        blockSigma <- matrix(rho, block_size, block_size)
        diag(blockSigma) <- 1

        cov_mat <- as.matrix(diag(p / block_size) %x% blockSigma)

        R <- chol(cov_mat)
        basis <- qr.Q(qr(matrix(rnorm(n*p), n)))
        X <- basis %*% R
    } else if(X_type == "MCC"){
        if(n %% (p+1) == 0){
            X <- lapply(1:(n/(p+1)), function(i){
                rbind(diag(rep(1, p)), rep(0, p))
            })
            X <- do.call(rbind, X)
            X <- scale(X, center = T, scale = F)
            X <- scale(X, center = F, scale = sqrt(colSums(X^2)))
        } else{
            cov_mat <- matrix(-1/p, p, p)
            diag(cov_mat) <- 1

            R <- chol(cov_mat)
            basis <- qr.Q(qr(matrix(rnorm(n*p), n)))
            X <- basis %*% R
        }
    } else if(X_type == "MCC_Block"){
        block_size <- 5
        
        blockSigma <- matrix(-1/block_size, block_size, block_size)
        diag(blockSigma) <- 1
        
        cov_mat <- as.matrix(diag(p / block_size) %x% blockSigma)
        
        R <- chol(cov_mat)
        basis <- qr.Q(qr(matrix(rnorm(n*p), n)))
        X <- basis %*% R
    }
    # X <- scale(X, center = FALSE, scale = sqrt(colSums(X^2)))

    return(X)
}


# compute the t-vals of a linear regression test problem
lm_to_t <- function(y, X, Sigma = NULL){
    n <- NROW(X)
    p <- NCOL(X)

    if(is.null(Sigma)){
        Sigma <- solve(t(X) %*% X)
    }
    Xy <- t(X) %*% y
    df <- n - p

    zvals <- Sigma %*% Xy
    sigmahat <- as.numeric(sqrt((sum(y^2) - t(Xy) %*% zvals) / df))
    tvals <- zvals / sqrt(diag(Sigma)) / sigmahat

    return(list(tvals = tvals, df = df))
}

# apply BH method to a linear regression test problem
BH_lm <- function(y, X, side = "two", alpha,
                  weights = rep(1, NCOL(X)) / NCOL(X),
                  Sigma = NULL){

    t_result <- lm_to_t(y, X, Sigma)
    pvals <- pvals_t(t_result$tvals, t_result$df, side = "two")

    BH_result <-  BH_weighted(pvals, alpha, weights)

    return(BH_result)
}

## calibrate signal strength, modified from Lihua
BH_lm_calib <- function(X, pi1, noise = quote(rnorm(n)),
                        mu_posit_type, mu_size_type,
                        side,
                        nreps = 1000,
                        alpha = 0.05,
                        target = 0.3,
                        n_cores = 7){
    n <- nrow(X)
    p <- ncol(X)
    Sigma <- solve(t(X) %*% X)
    H <- X %*% Sigma %*% t(X)
    df <- n - p

    beta_list <- lapply(1:nreps, function(i){
        beta <- genmu(p, pi1, 1, mu_posit_type, mu_size_type)
        if (side == "right"){
            beta <- abs(beta)
        } else if (side == "left"){
            beta <- -abs(beta)
        }
        return(beta)
    })
    eps_list <- lapply(1:nreps, function(i){
        eval(noise)
    })

    registerDoParallel(n_cores)

    BH_power <- function(mu1){
        power <- unlist(foreach(i = 1:nreps) %dopar% {
            H0 <- beta_list[[i]] == 0
            beta <- beta_list[[i]] * mu1
            eps <- eps_list[[i]]
            y <- X %*% beta + eps

            rejs_BH <- BH_lm(y, X, side = "two", alpha, Sigma = Sigma)$rejs
            power_sample <- calc_FDP_power(rejs_BH, H0)[2]

            return(power_sample)
        })
        mean(power) - target
    }

    lower <- 0
    upper <- 10
    while (TRUE & upper < 1000){
        tmp <- try(uniroot(BH_power, c(lower, upper))$root)
        if (class(tmp) == "try-error"){
            upper <- upper * 2
        } else {
            return(tmp)
        }
    }
    return(NA)
}

genmu <- function(n, pi1, mu1,
                  posit_type = c("random", "fix"),
                  mu_type = 1:3){
    m <- ceiling(n * pi1)
    posit_type <- posit_type[1]
    mu_type <- mu_type[1]
    if (posit_type == "random"){
        inds <- seq(1, n, floor(1 / pi1))[1:m]
    } else if (posit_type == "fix"){
        inds <- 1:m
    }
    mu <- rep(0, n)
    altmu <- switch(mu_type,
                    `1` = rep(1, m),
                    `2` = rnorm(m),
                    `3` = rep(1, m) + 0.15 * (2 * rbinom(m, 1, 0.5) - 1))
    mu[inds] <- mu1 * altmu
    mu
}

calc_FDP_power <- function(rejs, H0, sign_predict = NULL, sign_beta = NULL){
    nrejs <- length(rejs)

    false_discovery <- length(intersect(rejs, which(H0)))
    true_discovery <- nrejs - false_discovery

    FDP <- false_discovery / max(nrejs, 1)
    power <- true_discovery / max(sum(!H0), 1)

    if(!is.null(sign_predict)){
        false_dir <- sum((sign_predict * sign_beta)[rejs] <= 0)
        true_dir <- nrejs - false_dir

        FDP_dir <- false_dir / max(nrejs, 1)
        power_dir <- true_dir / length(sign_beta)
    } else{
        FDP_dir <- NA
        power_dir <- NA
    }

    return(c(FDP, power, FDP_dir, power_dir))
}
```

```{r plot}
draw_ineq <- function(ineq_invest){
    p_ineq <- ineq_invest$p_ineq %>%
        mutate(rej_type = as.character(2*kn_rej + nokn_rej)) %>%
        gather(side, value, ineq_L, ineq_R) %>%
        mutate(color = as.character(2 * (side == "ineq_R") + !kept))

    p_ineq %>% ggplot() +
        geom_point(aes(x = pval, y = value, color = color, shape = rej_type)) +
        # ylim(0, 0.01) +
        # xlim(0, 0.01) +
        labs(x = "right-sided p-value of j", y = "value of LHS or RHS",
             shape = "Shape: LHS Rej") +
        scale_shape_manual(labels = c("0" = "no", "1" = "not-kn", "2" = "kn", "3" = "both"),
                           values = c("0" = 20, "1" = 4, "2" = 1, "3" = 13)) +
        scale_color_manual(labels = c("0" = "LHS (kept)", "1" = "LHS (skip)",
                                      "2" = "RHS (kept)", "3" = "RHS (skip)"),
                           values = c("0" = "dodgerblue1", "1" = "dodgerblue4",
                                      "2" = "firebrick1", "3" = "firebrick4"))
}

draw_kn_stat <- function(ineq_invest, invest_j, SRL = F){
    eskn_rej_mc <- data.frame(ineq_invest$eskn_rej_mc) %>%
        gather(hypo, kn_rej, starts_with("X"))
    
    x <- ineq_invest$kn_stat_nodes$vjy_nodes
    y1 <- ineq_invest$kn_stat_nodes$kn_abs_stat_j
    y2 <- ineq_invest$kn_stat_nodes$kn_stat_thrs
    bandwidth <- max(abs(diff(x)))
    x_range <- c(min(x), max(x))
    F1 <- locpoly(x, y1, bandwidth=bandwidth, degree=1, gridsize = 100, range.x = x_range)
    F2 <- locpoly(x, y2, bandwidth=bandwidth*2, degree=1, gridsize = 100, range.x = x_range)

    data.frame(ineq_invest$kn_stats_mc) %>%
        mutate(pval_j = ineq_invest$p_ineq$pval,
               yvj = ineq_invest$vjy_mc) %>%
        gather(hypo, kn_stat, starts_with("X")) %>%
        mutate(this_j = (hypo == paste0("X", invest_j)),
               eskn_rej = eskn_rej_mc$kn_rej) %>%
        ggplot(aes(x = yvj , y = abs(kn_stat), group = hypo, color = this_j)) +
        geom_line(alpha = 0.5, aes(size = this_j)) +
        scale_size_manual(values = c(0, 1), breaks = c(F, T)) +
        geom_point(aes(alpha = eskn_rej)) +
        scale_alpha_manual(values = c(0, 1), breaks = c(F, T)) +
        geom_line(data = data.frame(vjy = F1$x,
                                    value = (F1$y),
                                    hypo = invest_j,
                                    this_j = T), aes(x = vjy, y = value), color = "black") +
        geom_point(data = data.frame(vjy = x,
                                     value = (y1),
                                     hypo = invest_j,
                                     this_j = T), aes(x = vjy, y = value), color = "black") +
        geom_line(data = data.frame(vjy = F2$x,
                                    value = (F2$y),
                                    hypo = invest_j,
                                    this_j = T), aes(x = vjy, y = value), color = "blue") +
        geom_point(data = data.frame(vjy = x,
                                     value = (y2),
                                     hypo = invest_j,
                                     this_j = T), aes(x = vjy, y = value), color = "blue") +
        geom_line(data = data.frame(vjy = ineq_invest$vjy_mc,
                                    kn_stat_thres = (ineq_invest$kn_stat_thres),
                                    hypo = invest_j,
                                    this_j = T), aes(x = vjy, y = kn_stat_thres), color = "blue")
}

draw_pval_cdf <- function(pval_mc, weights_mc, sample_region, df){
    x_seq <- seq(from = 0, to = 1, length.out = 500)
    
    emp_cdf <- sapply(x_seq, function(x){
        sum((pval_mc <= x) * weights_mc)
    }) / sum(weights_mc)
    
    region_left <- pt(sample_region$left, df = df, lower.tail = FALSE)
    region_right <- pt(sample_region$right, df = df, lower.tail = FALSE)
    ref_cdf <- sapply(x_seq, function(x){
        sum(x - region_left[region_left <= x]) - sum(x - region_right[region_right <= x])
    }) / sum(region_right - region_left)
    
    data <- data.frame(x = x_seq, CDF = emp_cdf, type = "empirical") %>%
        rbind(data.frame(x = x_seq, CDF = ref_cdf, type = "theoretical"))
    

    ggplot(data) +
        geom_line(aes(x = x, y = CDF, color = type)) + 
        labs(title = "CDF of right-sided p-value of H_j")
}

# P(a + b^T z <= 0 | \|z\|) for z ~ n(0, I_{df + 1} \sigma^2). See 11.summary Lemma 5
prob_sphere_onto_dir <- function(df, a, b_norm2, z_norm2){
    return(pt(-a * sqrt(df) / sqrt(pmax(b_norm2 * z_norm2 - a^2, 0)), df = df))
}

draw_yres_cdf <- function(y_Pi_Xk1_mc, weights_mc, z_norm2, df){
    bound <- min(sqrt(z_norm2), max(abs(y_Pi_Xk1_mc)) * 1.1)
    x_seq <- seq(from = -bound, to = bound, length.out = 500)
    
    emp_cdf <- sapply(x_seq, function(x){
        sum((y_Pi_Xk1_mc <= x) * weights_mc)
    }) / sum(weights_mc)
    
    ref_cdf <- sapply(x_seq, function(x){
        prob_sphere_onto_dir(df, -x, 1, z_norm2)
    })
    
    data <- data.frame(x = x_seq, CDF = emp_cdf, type = "empirical") %>%
        rbind(data.frame(x = x_seq, CDF = ref_cdf, type = "theoretical"))
    

    ggplot(data) +
        geom_line(aes(x = x, y = CDF, color = type)) + 
        labs(title = "CDF of y projected on to a unit vector in X^perp")
}
```

```{r run_test, fig.height=4, fig.width=6}
p <- 100
n <- p*3

mc_size <- 500
target <- 0.5

alpha <- 0.2
invest_j <- 21
#31, 6

ineq_invest <- invest_ineq(n, p, mc_size, X_type = "MCC", target, alpha,
                           alt_num = 10, y_seed = 12,
                           invest_j,
                           naive_sampler = F,
                           kn_reg_method = "local_lin_reg",
                           statistic = stat.glmnet_coefdiff_lm)


draw_ineq(ineq_invest)

draw_kn_stat(ineq_invest, invest_j, SRL = F)

draw_pval_cdf(ineq_invest$pval_mc, ineq_invest$weights_mc, ineq_invest$sample_region, df = n-p)

draw_yres_cdf(ineq_invest$y_Pi_Xk1_mc, ineq_invest$weights_mc, ineq_invest$z_norm2, df = n-p)

print("sample_mass")
print(sum(pt(ineq_invest$sample_region$right, df = n-p, lower.tail = T) -
              pt(ineq_invest$sample_region$left, df = n-p, lower.tail = T)))
print("p-val")
print(pt(ineq_invest$kn_rej_set$left, df = n-p, lower.tail = FALSE))
print(pt(ineq_invest$kn_rej_set$right, df = n-p, lower.tail = FALSE))
print("vjy")
print(ineq_invest$kn_rej_set$left_vjy)
print(ineq_invest$kn_rej_set$right_vjy)

## naive
# 0.0222158108558109
## sampler
# 0.0327135776748232


```


```{r eval=F}
alpha <- 0.05
mc_used <- read.csv(paste0("~/Workspace/Research/dBH-Knockoff_improve/18-Rpackage/cknockoff_expr/data/test_data/mc_used_pair/mc_used_", alpha, ".csv"), header = FALSE)
mc_sample_size_before_stop <- mc_used$V2

print(sum(mc_sample_size_before_stop))
hist(mc_sample_size_before_stop, breaks = 100)

mc_used <- read.csv(paste0("~/Workspace/Research/dBH-Knockoff_improve/18-Rpackage/cknockoff_expr/data/test_data/mc_used_single/mc_used_", alpha, ".csv"), header = FALSE)
mc_sample_size_before_stop <- mc_used$V2

print(sum(mc_sample_size_before_stop))
hist(mc_sample_size_before_stop, breaks = 100)
```



```{r eval=F}
p <- 100; n <- 300; k <- 15
X <- matrix(rnorm(n*p), n)
nonzero <- sample(p, k)
beta <- 3.5 * (1:p %in% nonzero)
y <- X %*% beta + rnorm(n)
print(which(1:p %in% nonzero))

# Basic usage
result <- cknockoff(X, y, alpha = 0.05, n_cores = 1)
print(result$selected)

result <- cknockoff(X, y, alpha = 0.05, n_cores = 1, Rhat_level = 1)
print(result$selected)

```







